{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fijmKftpUUM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas scikit-learn openml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1BGljIi7xHG",
        "outputId": "206002c1-a7a4-4b07-b6ee-374c3747770f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Collecting openml\n",
            "  Downloading openml-0.15.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting liac-arff>=2.4.0 (from openml)\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xmltodict (from openml)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openml) (2.32.3)\n",
            "Collecting minio (from openml)\n",
            "  Downloading minio-7.2.10-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from openml) (17.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openml) (4.66.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from openml) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from minio->openml) (2024.8.30)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio->openml) (2.2.3)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio->openml) (23.1.0)\n",
            "Collecting pycryptodome (from minio->openml)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from minio->openml) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (3.10)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio->openml) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.22)\n",
            "Downloading openml-0.15.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.0/158.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading minio-7.2.10-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=3421a837639c37f486cafd46d2eda1cfe4ec8d9c7d3e6b970dc53d2652a6cc48\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: xmltodict, pycryptodome, liac-arff, minio, openml\n",
            "Successfully installed liac-arff-2.5.0 minio-7.2.10 openml-0.15.0 pycryptodome-3.21.0 xmltodict-0.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPnMvlRB8UdP",
        "outputId": "9233a472-8869-452b-afe9-a715952d38be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load tabular data from OpenML with preprocessing\n",
        "def load_openml_data(task_id):\n",
        "    task = openml.tasks.get_task(task_id)\n",
        "    dataset = openml.datasets.get_dataset(task.dataset_id)\n",
        "    X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "    X = imputer.fit_transform(X)\n",
        "\n",
        "    # Convert categorical columns in X to numerical codes\n",
        "    for col in range(X.shape[1]):\n",
        "        if isinstance(X[0, col], str):\n",
        "            X[:, col] = pd.factorize(X[:, col])[0]\n",
        "\n",
        "    # Convert target y to numeric if needed and ensure it's a numpy array\n",
        "    if isinstance(y[0], str):\n",
        "        y = pd.factorize(y)[0]\n",
        "    y = np.array(y)  # Ensure y is a numpy array\n",
        "\n",
        "    return X.astype(np.float32), y.astype(np.int64)\n",
        "\n",
        "# Define a custom dataset for tabular data\n",
        "class TabularDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# Define a simple ResNet-like model for tabular data\n",
        "class ResNetTabular(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(ResNetTabular, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.fc1(x))\n",
        "        out = self.dropout(out)\n",
        "        out = self.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "# Get data loaders\n",
        "def get_data_loaders(X, y, batch_size):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "\n",
        "    train_dataset = TabularDataset(X_train, np.array(y_train))\n",
        "    val_dataset = TabularDataset(X_val, np.array(y_val))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "-ctJ1HAC_mLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09447b48-4b27-4097-975c-a8ea57ee3c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openml:No permission to create OpenML directory at /root/.config/openml! This can result in OpenML-Python not working properly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID1: 14965"
      ],
      "metadata": {
        "id": "Av3Ht0glwhhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 14965  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytlHOSnbUwoH",
        "outputId": "ad9970c7-e61f-4cad-8a9d-bcefa52cf340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4260\n",
            "Epoch [2/10], Loss: 0.5946\n",
            "Epoch [3/10], Loss: 0.1920\n",
            "Epoch [4/10], Loss: 0.2464\n",
            "Epoch [5/10], Loss: 0.0870\n",
            "Epoch [6/10], Loss: 0.1267\n",
            "Epoch [7/10], Loss: 0.0284\n",
            "Epoch [8/10], Loss: 0.2418\n",
            "Epoch [9/10], Loss: 0.1787\n",
            "Epoch [10/10], Loss: 0.5847\n",
            "Accuracy: 0.8986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID2: 9977"
      ],
      "metadata": {
        "id": "_bEEFrVDxJk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9977  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdrtsPQzVGEP",
        "outputId": "779ef7cd-fbe5-4b1c-a490-4e270765c9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.0974\n",
            "Epoch [2/10], Loss: 0.2079\n",
            "Epoch [3/10], Loss: 0.2211\n",
            "Epoch [4/10], Loss: 0.1062\n",
            "Epoch [5/10], Loss: 0.2668\n",
            "Epoch [6/10], Loss: 0.1894\n",
            "Epoch [7/10], Loss: 0.0312\n",
            "Epoch [8/10], Loss: 0.0508\n",
            "Epoch [9/10], Loss: 0.2419\n",
            "Epoch [10/10], Loss: 0.0775\n",
            "Accuracy: 0.9569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hz-jF53KD4A"
      },
      "source": [
        "# Task ID3: 34539"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 34539  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPGAxWnaVG-R",
        "outputId": "fba58a4a-059b-420f-bbba-1f9af171b112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.0910\n",
            "Epoch [2/10], Loss: 0.4356\n",
            "Epoch [3/10], Loss: 0.0497\n",
            "Epoch [4/10], Loss: 0.4178\n",
            "Epoch [5/10], Loss: 0.0615\n",
            "Epoch [6/10], Loss: 0.0547\n",
            "Epoch [7/10], Loss: 0.4389\n",
            "Epoch [8/10], Loss: 0.0719\n",
            "Epoch [9/10], Loss: 0.0612\n",
            "Epoch [10/10], Loss: 0.0526\n",
            "Accuracy: 0.9437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ1lM1Bv99qs"
      },
      "source": [
        "# Task ID4: 146606"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146606  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kqbDzHdVHuL",
        "outputId": "8ea9bb2f-87af-4b33-f2ba-2a7bba7a99aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7213\n",
            "Epoch [2/10], Loss: 0.4284\n",
            "Epoch [3/10], Loss: 0.6582\n",
            "Epoch [4/10], Loss: 0.5026\n",
            "Epoch [5/10], Loss: 0.6339\n",
            "Epoch [6/10], Loss: 0.4914\n",
            "Epoch [7/10], Loss: 0.3908\n",
            "Epoch [8/10], Loss: 0.5078\n",
            "Epoch [9/10], Loss: 0.4592\n",
            "Epoch [10/10], Loss: 0.5521\n",
            "Accuracy: 0.7110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agXkkvFj-uRE"
      },
      "source": [
        "# Task ID5: 7592\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 7592  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6UmYlAHVIyM",
        "outputId": "045be0fa-13d9-4a58-ddf5-0f6092c58f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.0014\n",
            "Epoch [2/10], Loss: 0.6058\n",
            "Epoch [3/10], Loss: 0.8110\n",
            "Epoch [4/10], Loss: 0.0000\n",
            "Epoch [5/10], Loss: 0.0696\n",
            "Epoch [6/10], Loss: 0.3649\n",
            "Epoch [7/10], Loss: 0.7185\n",
            "Epoch [8/10], Loss: 0.0277\n",
            "Epoch [9/10], Loss: 0.0139\n",
            "Epoch [10/10], Loss: 0.0697\n",
            "Accuracy: 0.8547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qB-NZ-t-wyd"
      },
      "source": [
        "# Task ID6: 146195\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146195  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct9rKIAAVJlJ",
        "outputId": "193ffa5d-6723-4e12-d789-14444de40b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8686\n",
            "Epoch [2/10], Loss: 0.9432\n",
            "Epoch [3/10], Loss: 0.6589\n",
            "Epoch [4/10], Loss: 0.7128\n",
            "Epoch [5/10], Loss: 0.8151\n",
            "Epoch [6/10], Loss: 0.9076\n",
            "Epoch [7/10], Loss: 0.5395\n",
            "Epoch [8/10], Loss: 0.7531\n",
            "Epoch [9/10], Loss: 0.4656\n",
            "Epoch [10/10], Loss: 0.6060\n",
            "Accuracy: 0.7419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-6lP2ED-yYw"
      },
      "source": [
        "# Task ID7: 167119\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 167119  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2VTHfgFVKnR",
        "outputId": "08f8b198-98cf-48c2-95c3-90059de13b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7850\n",
            "Epoch [2/10], Loss: 0.5707\n",
            "Epoch [3/10], Loss: 0.5016\n",
            "Epoch [4/10], Loss: 0.4219\n",
            "Epoch [5/10], Loss: 0.5030\n",
            "Epoch [6/10], Loss: 0.2640\n",
            "Epoch [7/10], Loss: 0.3358\n",
            "Epoch [8/10], Loss: 0.5580\n",
            "Epoch [9/10], Loss: 0.3370\n",
            "Epoch [10/10], Loss: 0.6294\n",
            "Accuracy: 0.8168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhMkxXLjFYC_"
      },
      "source": [
        "# Task ID8: 167120\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 167120  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh5EOzGIVMMx",
        "outputId": "c67fd076-fc01-45e3-edd1-f7059ea5839c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6991\n",
            "Epoch [2/10], Loss: 0.6941\n",
            "Epoch [3/10], Loss: 0.6848\n",
            "Epoch [4/10], Loss: 0.6814\n",
            "Epoch [5/10], Loss: 0.6823\n",
            "Epoch [6/10], Loss: 0.7074\n",
            "Epoch [7/10], Loss: 0.6843\n",
            "Epoch [8/10], Loss: 0.6936\n",
            "Epoch [9/10], Loss: 0.6967\n",
            "Epoch [10/10], Loss: 0.6904\n",
            "Accuracy: 0.5147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Or_hKHXYB39"
      },
      "source": [
        "# Task ID11: \t168331\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 168331 # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2qsoS8HVNad",
        "outputId": "ab09177b-8aed-44e3-ec80-da4ab3478094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.2453\n",
            "Epoch [2/10], Loss: 1.2675\n",
            "Epoch [3/10], Loss: 1.3478\n",
            "Epoch [4/10], Loss: 1.6738\n",
            "Epoch [5/10], Loss: 1.0183\n",
            "Epoch [6/10], Loss: 0.6520\n",
            "Epoch [7/10], Loss: 1.0676\n",
            "Epoch [8/10], Loss: 1.2553\n",
            "Epoch [9/10], Loss: 1.3280\n",
            "Epoch [10/10], Loss: 1.3362\n",
            "Accuracy: 0.6153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUMhEOrBdFAA"
      },
      "source": [
        "# Task ID12: \t168330\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 168330  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWSRP0DWVOQS",
        "outputId": "0f42bf2a-2a16-4784-dbe7-3e8110c43914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.9018\n",
            "Epoch [2/10], Loss: 0.9688\n",
            "Epoch [3/10], Loss: 1.2281\n",
            "Epoch [4/10], Loss: 0.5237\n",
            "Epoch [5/10], Loss: 0.6596\n",
            "Epoch [6/10], Loss: 0.8224\n",
            "Epoch [7/10], Loss: 0.5093\n",
            "Epoch [8/10], Loss: 0.7616\n",
            "Epoch [9/10], Loss: 0.5017\n",
            "Epoch [10/10], Loss: 0.7088\n",
            "Accuracy: 0.6976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3yrnlEGULX7"
      },
      "source": [
        "# Task ID13: \t168335\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 168335  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lySDofyjVPC5",
        "outputId": "d34b2f21-0550-4428-bb80-0218bba0bafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2640\n",
            "Epoch [2/10], Loss: 0.3778\n",
            "Epoch [3/10], Loss: 0.2037\n",
            "Epoch [4/10], Loss: 0.4725\n",
            "Epoch [5/10], Loss: 0.1526\n",
            "Epoch [6/10], Loss: 0.2035\n",
            "Epoch [7/10], Loss: 0.2507\n",
            "Epoch [8/10], Loss: 0.0468\n",
            "Epoch [9/10], Loss: 0.0393\n",
            "Epoch [10/10], Loss: 0.0797\n",
            "Accuracy: 0.9237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "065Jhn3bUN3E"
      },
      "source": [
        "\n",
        "# Task ID16: \t146212\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146212  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5heVK7IFVQVd",
        "outputId": "47f292e2-9b8f-462e-e9ef-c812c338bd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.0848\n",
            "Epoch [2/10], Loss: 0.0027\n",
            "Epoch [3/10], Loss: 0.0044\n",
            "Epoch [4/10], Loss: 0.0607\n",
            "Epoch [5/10], Loss: 0.0098\n",
            "Epoch [6/10], Loss: 0.0027\n",
            "Epoch [7/10], Loss: 0.0029\n",
            "Epoch [8/10], Loss: 0.0078\n",
            "Epoch [9/10], Loss: 0.0013\n",
            "Epoch [10/10], Loss: 0.0029\n",
            "Accuracy: 0.9967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPP_6tsjUQVe"
      },
      "source": [
        "# Task ID19: \t168868\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 168868  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8udT0ObfVRcp",
        "outputId": "48911c75-e331-4248-ffd7-615c9c3a6320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.0231\n",
            "Epoch [2/10], Loss: 0.0178\n",
            "Epoch [3/10], Loss: 0.0001\n",
            "Epoch [4/10], Loss: 0.0014\n",
            "Epoch [5/10], Loss: 0.0202\n",
            "Epoch [6/10], Loss: 0.0688\n",
            "Epoch [7/10], Loss: 0.0147\n",
            "Epoch [8/10], Loss: 0.0085\n",
            "Epoch [9/10], Loss: 0.0034\n",
            "Epoch [10/10], Loss: 0.0060\n",
            "Accuracy: 0.9904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID20: 31"
      ],
      "metadata": {
        "id": "UkfKJeLtuxt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 31  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR9YiEEE-FfZ",
        "outputId": "d5cc0db9-6168-4ff5-8a8e-d0601e167af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6869\n",
            "Epoch [2/10], Loss: 0.5056\n",
            "Epoch [3/10], Loss: 0.5218\n",
            "Epoch [4/10], Loss: 0.4387\n",
            "Epoch [5/10], Loss: 0.5354\n",
            "Epoch [6/10], Loss: 0.5089\n",
            "Epoch [7/10], Loss: 0.6623\n",
            "Epoch [8/10], Loss: 0.5546\n",
            "Epoch [9/10], Loss: 0.5116\n",
            "Epoch [10/10], Loss: 0.5411\n",
            "Accuracy: 0.7700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID21: 10101"
      ],
      "metadata": {
        "id": "u6DpJWyJu_Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 10101  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tn5a68V-Ihb",
        "outputId": "26de17b5-3d18-4f54-94ea-f754dba36bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5918\n",
            "Epoch [2/10], Loss: 0.4164\n",
            "Epoch [3/10], Loss: 0.4128\n",
            "Epoch [4/10], Loss: 0.5102\n",
            "Epoch [5/10], Loss: 0.5324\n",
            "Epoch [6/10], Loss: 0.5481\n",
            "Epoch [7/10], Loss: 0.4402\n",
            "Epoch [8/10], Loss: 0.5139\n",
            "Epoch [9/10], Loss: 0.4102\n",
            "Epoch [10/10], Loss: 0.6876\n",
            "Accuracy: 0.7667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID22: \t3913"
      ],
      "metadata": {
        "id": "L4PMg4K1vD9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3913  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKYE6nMH-Lsa",
        "outputId": "b4416930-6f6a-4407-ab5d-2231322aa97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5112\n",
            "Epoch [2/10], Loss: 0.2776\n",
            "Epoch [3/10], Loss: 1.0583\n",
            "Epoch [4/10], Loss: 0.2997\n",
            "Epoch [5/10], Loss: 0.0267\n",
            "Epoch [6/10], Loss: 0.0063\n",
            "Epoch [7/10], Loss: 0.0171\n",
            "Epoch [8/10], Loss: 0.0147\n",
            "Epoch [9/10], Loss: 0.0334\n",
            "Epoch [10/10], Loss: 0.0413\n",
            "Accuracy: 0.8667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID23: 3"
      ],
      "metadata": {
        "id": "6UVYtFS5vFdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3 # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK8OI4mO-PR3",
        "outputId": "1f0f4e06-4c78-4a5b-ada2-36f643f0163d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.3384\n",
            "Epoch [2/10], Loss: 0.1961\n",
            "Epoch [3/10], Loss: 0.1481\n",
            "Epoch [4/10], Loss: 0.1710\n",
            "Epoch [5/10], Loss: 0.1064\n",
            "Epoch [6/10], Loss: 0.1497\n",
            "Epoch [7/10], Loss: 0.0458\n",
            "Epoch [8/10], Loss: 0.1258\n",
            "Epoch [9/10], Loss: 0.0724\n",
            "Epoch [10/10], Loss: 0.0192\n",
            "Accuracy: 0.9672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID24: 3917"
      ],
      "metadata": {
        "id": "vyRHJUzZvHFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3917  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYni-Y0T-R7q",
        "outputId": "38aa6975-4830-4476-a673-dec6457c4c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4596\n",
            "Epoch [2/10], Loss: 0.5719\n",
            "Epoch [3/10], Loss: 0.4327\n",
            "Epoch [4/10], Loss: 0.3523\n",
            "Epoch [5/10], Loss: 0.2566\n",
            "Epoch [6/10], Loss: 0.4604\n",
            "Epoch [7/10], Loss: 0.4556\n",
            "Epoch [8/10], Loss: 0.1894\n",
            "Epoch [9/10], Loss: 0.3987\n",
            "Epoch [10/10], Loss: 0.3939\n",
            "Accuracy: 0.8555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID25: 9957"
      ],
      "metadata": {
        "id": "dzf2O5cvvLhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9957 # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnCU6HZ1-VD_",
        "outputId": "8594f1a2-e3db-467e-f247-5b0f923df596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6627\n",
            "Epoch [2/10], Loss: 0.8670\n",
            "Epoch [3/10], Loss: 0.4477\n",
            "Epoch [4/10], Loss: 0.7525\n",
            "Epoch [5/10], Loss: 0.3378\n",
            "Epoch [6/10], Loss: 0.2250\n",
            "Epoch [7/10], Loss: 0.1704\n",
            "Epoch [8/10], Loss: 0.3046\n",
            "Epoch [9/10], Loss: 0.1955\n",
            "Epoch [10/10], Loss: 0.1029\n",
            "Accuracy: 0.8768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID26: 9946"
      ],
      "metadata": {
        "id": "xbL7uSt3vBp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9946  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csjO4u3v-Ycg",
        "outputId": "f9687932-afa7-47c2-e516-eb390ad4fd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5340\n",
            "Epoch [2/10], Loss: 0.2510\n",
            "Epoch [3/10], Loss: 0.1707\n",
            "Epoch [4/10], Loss: 0.0688\n",
            "Epoch [5/10], Loss: 0.0360\n",
            "Epoch [6/10], Loss: 0.6044\n",
            "Epoch [7/10], Loss: 0.1031\n",
            "Epoch [8/10], Loss: 0.1066\n",
            "Epoch [9/10], Loss: 0.0260\n",
            "Epoch [10/10], Loss: 0.0106\n",
            "Accuracy: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID27: 3918"
      ],
      "metadata": {
        "id": "4_3XUL5zOr31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3918  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiCG0yJ-GR5y",
        "outputId": "b037760b-9c9a-4ed0-f2f9-6b44faf984f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.3709\n",
            "Epoch [2/10], Loss: 0.1950\n",
            "Epoch [3/10], Loss: 0.2589\n",
            "Epoch [4/10], Loss: 0.1441\n",
            "Epoch [5/10], Loss: 0.1903\n",
            "Epoch [6/10], Loss: 0.2888\n",
            "Epoch [7/10], Loss: 0.2672\n",
            "Epoch [8/10], Loss: 0.1748\n",
            "Epoch [9/10], Loss: 0.1271\n",
            "Epoch [10/10], Loss: 0.0570\n",
            "Accuracy: 0.9234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID28: 3903"
      ],
      "metadata": {
        "id": "gMfLQ_viOsKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3903  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWDkzsiWGUlz",
        "outputId": "84b5f799-8301-48c2-fd88-96cd0636ab6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.1874\n",
            "Epoch [2/10], Loss: 0.0021\n",
            "Epoch [3/10], Loss: 0.0902\n",
            "Epoch [4/10], Loss: 0.0500\n",
            "Epoch [5/10], Loss: 0.2451\n",
            "Epoch [6/10], Loss: 0.0912\n",
            "Epoch [7/10], Loss: 0.2821\n",
            "Epoch [8/10], Loss: 0.0349\n",
            "Epoch [9/10], Loss: 0.0121\n",
            "Epoch [10/10], Loss: 0.2675\n",
            "Accuracy: 0.8946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID29: 37"
      ],
      "metadata": {
        "id": "p8r0_x-wOsYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 37  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuG830SqGVbv",
        "outputId": "5ea568b6-b38e-41d3-d17d-2bf241cc91f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7980\n",
            "Epoch [2/10], Loss: 0.5303\n",
            "Epoch [3/10], Loss: 0.4557\n",
            "Epoch [4/10], Loss: 0.3613\n",
            "Epoch [5/10], Loss: 0.2631\n",
            "Epoch [6/10], Loss: 0.2889\n",
            "Epoch [7/10], Loss: 0.7615\n",
            "Epoch [8/10], Loss: 0.6689\n",
            "Epoch [9/10], Loss: 0.3163\n",
            "Epoch [10/10], Loss: 1.0312\n",
            "Accuracy: 0.7727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID30: 9971"
      ],
      "metadata": {
        "id": "ZInQ-9WoOsu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9971  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VCXEp4MGWLh",
        "outputId": "d3b6dc8d-9afd-4213-dfe7-09c829dacd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7102\n",
            "Epoch [2/10], Loss: 0.6663\n",
            "Epoch [3/10], Loss: 0.6042\n",
            "Epoch [4/10], Loss: 0.5484\n",
            "Epoch [5/10], Loss: 0.5739\n",
            "Epoch [6/10], Loss: 0.5683\n",
            "Epoch [7/10], Loss: 0.4374\n",
            "Epoch [8/10], Loss: 0.5640\n",
            "Epoch [9/10], Loss: 0.4436\n",
            "Epoch [10/10], Loss: 0.5529\n",
            "Accuracy: 0.7521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID31: 9952"
      ],
      "metadata": {
        "id": "JXEaEKEaOtAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9952  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdLWKWR3GYSa",
        "outputId": "11831023-997e-4dc8-fd96-24e77ec53782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4420\n",
            "Epoch [2/10], Loss: 0.2358\n",
            "Epoch [3/10], Loss: 0.6512\n",
            "Epoch [4/10], Loss: 0.2106\n",
            "Epoch [5/10], Loss: 0.0253\n",
            "Epoch [6/10], Loss: 0.0595\n",
            "Epoch [7/10], Loss: 0.2756\n",
            "Epoch [8/10], Loss: 0.7425\n",
            "Epoch [9/10], Loss: 0.1605\n",
            "Epoch [10/10], Loss: 0.1029\n",
            "Accuracy: 0.8409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID32: 3902"
      ],
      "metadata": {
        "id": "pW00w70pOtPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3902 # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbY26bfxGZOZ",
        "outputId": "a677dcd4-b417-4364-a28b-6d5ffde7ea97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5660\n",
            "Epoch [2/10], Loss: 0.2736\n",
            "Epoch [3/10], Loss: 0.5322\n",
            "Epoch [4/10], Loss: 0.1324\n",
            "Epoch [5/10], Loss: 0.2318\n",
            "Epoch [6/10], Loss: 0.0899\n",
            "Epoch [7/10], Loss: 0.0418\n",
            "Epoch [8/10], Loss: 0.1281\n",
            "Epoch [9/10], Loss: 0.2423\n",
            "Epoch [10/10], Loss: 0.1533\n",
            "Accuracy: 0.9007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID33: 49"
      ],
      "metadata": {
        "id": "6zZ17oDlOtbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 49  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKe4kQ0qGgNe",
        "outputId": "22e1021f-9711-4f21-b8a3-ab47a623c034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6397\n",
            "Epoch [2/10], Loss: 0.6337\n",
            "Epoch [3/10], Loss: 0.6754\n",
            "Epoch [4/10], Loss: 0.5163\n",
            "Epoch [5/10], Loss: 0.5286\n",
            "Epoch [6/10], Loss: 0.5523\n",
            "Epoch [7/10], Loss: 0.5079\n",
            "Epoch [8/10], Loss: 0.6817\n",
            "Epoch [9/10], Loss: 0.4796\n",
            "Epoch [10/10], Loss: 0.5917\n",
            "Accuracy: 0.7448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID34: 43"
      ],
      "metadata": {
        "id": "U5j20q0COtoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 43  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxH-98QvGhAa",
        "outputId": "43111517-2b8c-4221-c308-f4a55b189cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.3681\n",
            "Epoch [2/10], Loss: 0.4118\n",
            "Epoch [3/10], Loss: 0.1910\n",
            "Epoch [4/10], Loss: 0.1333\n",
            "Epoch [5/10], Loss: 0.3396\n",
            "Epoch [6/10], Loss: 0.3177\n",
            "Epoch [7/10], Loss: 0.2570\n",
            "Epoch [8/10], Loss: 0.0715\n",
            "Epoch [9/10], Loss: 0.1488\n",
            "Epoch [10/10], Loss: 0.2670\n",
            "Accuracy: 0.9414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID35: 9978"
      ],
      "metadata": {
        "id": "I-iHZbecOt0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9978  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfcc7zTNGhoT",
        "outputId": "92b58122-f266-4f4b-e525-aaf8d6c6b199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2508\n",
            "Epoch [2/10], Loss: 0.0895\n",
            "Epoch [3/10], Loss: 0.2939\n",
            "Epoch [4/10], Loss: 0.2479\n",
            "Epoch [5/10], Loss: 0.1636\n",
            "Epoch [6/10], Loss: 0.0165\n",
            "Epoch [7/10], Loss: 0.0959\n",
            "Epoch [8/10], Loss: 0.0246\n",
            "Epoch [9/10], Loss: 0.0195\n",
            "Epoch [10/10], Loss: 0.0221\n",
            "Accuracy: 0.9428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID36: 10093"
      ],
      "metadata": {
        "id": "uysN5WV0Oxpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 10093 # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILLstvLvGiO3",
        "outputId": "8c196b68-3dbd-43fe-e9e8-fab27134ab14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.3740\n",
            "Epoch [2/10], Loss: 0.1824\n",
            "Epoch [3/10], Loss: 0.0304\n",
            "Epoch [4/10], Loss: 0.0635\n",
            "Epoch [5/10], Loss: 0.0438\n",
            "Epoch [6/10], Loss: 0.3713\n",
            "Epoch [7/10], Loss: 0.0670\n",
            "Epoch [8/10], Loss: 0.0077\n",
            "Epoch [9/10], Loss: 0.0743\n",
            "Epoch [10/10], Loss: 0.0029\n",
            "Accuracy: 0.9927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID37: 219"
      ],
      "metadata": {
        "id": "yGgmlLAKULw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 219  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i9uhhDJGi97",
        "outputId": "7a0fb322-5631-4b29-849f-2109e0423607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4165\n",
            "Epoch [2/10], Loss: 0.5305\n",
            "Epoch [3/10], Loss: 0.4529\n",
            "Epoch [4/10], Loss: 0.4580\n",
            "Epoch [5/10], Loss: 0.6772\n",
            "Epoch [6/10], Loss: 0.5069\n",
            "Epoch [7/10], Loss: 0.5180\n",
            "Epoch [8/10], Loss: 0.2981\n",
            "Epoch [9/10], Loss: 0.5443\n",
            "Epoch [10/10], Loss: 0.4480\n",
            "Accuracy: 0.7951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID38: 9976"
      ],
      "metadata": {
        "id": "1SP0wCLxUMfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9976  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHZZtmHpGj1-",
        "outputId": "167fafa7-1d73-4cbe-e77b-9060782169b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6845\n",
            "Epoch [2/10], Loss: 0.5947\n",
            "Epoch [3/10], Loss: 0.4864\n",
            "Epoch [4/10], Loss: 0.6458\n",
            "Epoch [5/10], Loss: 0.4855\n",
            "Epoch [6/10], Loss: 0.2363\n",
            "Epoch [7/10], Loss: 0.2353\n",
            "Epoch [8/10], Loss: 0.0765\n",
            "Epoch [9/10], Loss: 0.3338\n",
            "Epoch [10/10], Loss: 0.2892\n",
            "Accuracy: 0.5731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID39: 6"
      ],
      "metadata": {
        "id": "S65JoO55UMry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 6  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyQs1IqdGk1N",
        "outputId": "d62adcd6-5041-4238-857c-dd5e477d2474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.9848\n",
            "Epoch [2/10], Loss: 1.1941\n",
            "Epoch [3/10], Loss: 1.0551\n",
            "Epoch [4/10], Loss: 1.0708\n",
            "Epoch [5/10], Loss: 1.2120\n",
            "Epoch [6/10], Loss: 0.8768\n",
            "Epoch [7/10], Loss: 1.1595\n",
            "Epoch [8/10], Loss: 0.5226\n",
            "Epoch [9/10], Loss: 1.2247\n",
            "Epoch [10/10], Loss: 0.6530\n",
            "Accuracy: 0.8377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID40: 53"
      ],
      "metadata": {
        "id": "BEsQTY0-UM3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 53  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vybhbcENGl07",
        "outputId": "5032a44a-8f5a-44ff-b965-91a9647d4dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.3027\n",
            "Epoch [2/10], Loss: 1.2649\n",
            "Epoch [3/10], Loss: 0.9712\n",
            "Epoch [4/10], Loss: 0.6766\n",
            "Epoch [5/10], Loss: 0.8990\n",
            "Epoch [6/10], Loss: 0.5625\n",
            "Epoch [7/10], Loss: 0.7454\n",
            "Epoch [8/10], Loss: 0.9923\n",
            "Epoch [9/10], Loss: 0.5062\n",
            "Epoch [10/10], Loss: 0.5359\n",
            "Accuracy: 0.7824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID41: 11"
      ],
      "metadata": {
        "id": "dI13mhhGUNDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 11  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwpsPjLuGmaD",
        "outputId": "7cae04d4-888b-4377-8bd2-865fadc2e2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.9080\n",
            "Epoch [2/10], Loss: 0.8733\n",
            "Epoch [3/10], Loss: 0.8591\n",
            "Epoch [4/10], Loss: 0.4565\n",
            "Epoch [5/10], Loss: 0.5395\n",
            "Epoch [6/10], Loss: 0.4304\n",
            "Epoch [7/10], Loss: 0.2466\n",
            "Epoch [8/10], Loss: 0.2302\n",
            "Epoch [9/10], Loss: 0.3437\n",
            "Epoch [10/10], Loss: 0.4615\n",
            "Accuracy: 0.9040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID42: 15"
      ],
      "metadata": {
        "id": "L6e6nkQbUNPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 15  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQQnv5aSGnDE",
        "outputId": "e4e8a1c6-35ca-4e44-99b4-34f88560d58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4783\n",
            "Epoch [2/10], Loss: 0.1655\n",
            "Epoch [3/10], Loss: 0.3796\n",
            "Epoch [4/10], Loss: 0.0724\n",
            "Epoch [5/10], Loss: 0.0301\n",
            "Epoch [6/10], Loss: 0.2333\n",
            "Epoch [7/10], Loss: 0.6262\n",
            "Epoch [8/10], Loss: 0.0076\n",
            "Epoch [9/10], Loss: 0.0314\n",
            "Epoch [10/10], Loss: 0.0277\n",
            "Accuracy: 0.9714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID43: 16"
      ],
      "metadata": {
        "id": "iNhJDlrKUNat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 16  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wkqL0E1Gnz-",
        "outputId": "69294c39-7296-488b-9d0a-c1ae9204b50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.9781\n",
            "Epoch [2/10], Loss: 0.8679\n",
            "Epoch [3/10], Loss: 0.6595\n",
            "Epoch [4/10], Loss: 0.3748\n",
            "Epoch [5/10], Loss: 0.2482\n",
            "Epoch [6/10], Loss: 0.5316\n",
            "Epoch [7/10], Loss: 0.1599\n",
            "Epoch [8/10], Loss: 0.2725\n",
            "Epoch [9/10], Loss: 0.1761\n",
            "Epoch [10/10], Loss: 0.1800\n",
            "Accuracy: 0.9575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID44: 14"
      ],
      "metadata": {
        "id": "Ng32K-haUNl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 14  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne_sW0L_Gp0c",
        "outputId": "364326de-c2ce-4973-d257-f73bd0eb9fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.9336\n",
            "Epoch [2/10], Loss: 1.2328\n",
            "Epoch [3/10], Loss: 0.7231\n",
            "Epoch [4/10], Loss: 0.7118\n",
            "Epoch [5/10], Loss: 0.5210\n",
            "Epoch [6/10], Loss: 0.5873\n",
            "Epoch [7/10], Loss: 0.6012\n",
            "Epoch [8/10], Loss: 0.6615\n",
            "Epoch [9/10], Loss: 0.3988\n",
            "Epoch [10/10], Loss: 0.2812\n",
            "Accuracy: 0.8275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID45: 32"
      ],
      "metadata": {
        "id": "WL9ZOy4AUNws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 32  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xghdE8axGrBJ",
        "outputId": "a3d5adde-723b-46bd-ded3-4d75f57ee614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6213\n",
            "Epoch [2/10], Loss: 0.2162\n",
            "Epoch [3/10], Loss: 0.5217\n",
            "Epoch [4/10], Loss: 0.2088\n",
            "Epoch [5/10], Loss: 0.1713\n",
            "Epoch [6/10], Loss: 0.0627\n",
            "Epoch [7/10], Loss: 0.1875\n",
            "Epoch [8/10], Loss: 0.2259\n",
            "Epoch [9/10], Loss: 0.1253\n",
            "Epoch [10/10], Loss: 0.1890\n",
            "Accuracy: 0.9809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID46: 3549"
      ],
      "metadata": {
        "id": "ewtX2G2PUN7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3549  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoxmCuN4GrrU",
        "outputId": "bc0ae973-955b-40d9-e905-2c3610ec2e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.0427\n",
            "Epoch [2/10], Loss: 0.6480\n",
            "Epoch [3/10], Loss: 0.2173\n",
            "Epoch [4/10], Loss: 0.3367\n",
            "Epoch [5/10], Loss: 0.1164\n",
            "Epoch [6/10], Loss: 0.0216\n",
            "Epoch [7/10], Loss: 0.0136\n",
            "Epoch [8/10], Loss: 0.0206\n",
            "Epoch [9/10], Loss: 0.0112\n",
            "Epoch [10/10], Loss: 0.0094\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID47: 12"
      ],
      "metadata": {
        "id": "7vNpomuQUOGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 12 # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIbojVFhGsrc",
        "outputId": "bc05b9c0-3680-41d7-fc1d-89466db37f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.0848\n",
            "Epoch [2/10], Loss: 0.4446\n",
            "Epoch [3/10], Loss: 0.3421\n",
            "Epoch [4/10], Loss: 0.1097\n",
            "Epoch [5/10], Loss: 0.2730\n",
            "Epoch [6/10], Loss: 0.1099\n",
            "Epoch [7/10], Loss: 0.1292\n",
            "Epoch [8/10], Loss: 0.0717\n",
            "Epoch [9/10], Loss: 0.1066\n",
            "Epoch [10/10], Loss: 0.0456\n",
            "Accuracy: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID48: 9981"
      ],
      "metadata": {
        "id": "fWOstqIAUORB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9981  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulPEdAxnGtfj",
        "outputId": "217ba251-70f1-49dd-c4ed-5974d3e9cb73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.0943\n",
            "Epoch [2/10], Loss: 1.6230\n",
            "Epoch [3/10], Loss: 0.9115\n",
            "Epoch [4/10], Loss: 0.4620\n",
            "Epoch [5/10], Loss: 0.3348\n",
            "Epoch [6/10], Loss: 0.3186\n",
            "Epoch [7/10], Loss: 0.0979\n",
            "Epoch [8/10], Loss: 0.1229\n",
            "Epoch [9/10], Loss: 0.1042\n",
            "Epoch [10/10], Loss: 0.1168\n",
            "Accuracy: 0.9491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID49: 18"
      ],
      "metadata": {
        "id": "lhXlnoGdUObZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 18  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVN3pwj1GuHt",
        "outputId": "ff496e56-f45a-4c9a-84f2-a1d728c076b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.7950\n",
            "Epoch [2/10], Loss: 1.5099\n",
            "Epoch [3/10], Loss: 1.0113\n",
            "Epoch [4/10], Loss: 0.8657\n",
            "Epoch [5/10], Loss: 0.7223\n",
            "Epoch [6/10], Loss: 0.6450\n",
            "Epoch [7/10], Loss: 0.7077\n",
            "Epoch [8/10], Loss: 0.9311\n",
            "Epoch [9/10], Loss: 0.9843\n",
            "Epoch [10/10], Loss: 0.7082\n",
            "Accuracy: 0.7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID50: 28"
      ],
      "metadata": {
        "id": "WJJ0ZiGDUOnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 28  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm1Jjh0NGuyc",
        "outputId": "661cd1fd-8289-4eed-dee6-ad50107b8561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2769\n",
            "Epoch [2/10], Loss: 0.3782\n",
            "Epoch [3/10], Loss: 0.4242\n",
            "Epoch [4/10], Loss: 0.0945\n",
            "Epoch [5/10], Loss: 0.2345\n",
            "Epoch [6/10], Loss: 0.0353\n",
            "Epoch [7/10], Loss: 0.0238\n",
            "Epoch [8/10], Loss: 0.1468\n",
            "Epoch [9/10], Loss: 0.0908\n",
            "Epoch [10/10], Loss: 0.0219\n",
            "Accuracy: 0.9751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID51: 2074"
      ],
      "metadata": {
        "id": "cDW6wxhbUOzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 2074  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHR5J-jmGvee",
        "outputId": "f3283f6c-62c6-4159-fa32-23b13485f7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2922\n",
            "Epoch [2/10], Loss: 0.3533\n",
            "Epoch [3/10], Loss: 0.4110\n",
            "Epoch [4/10], Loss: 0.3735\n",
            "Epoch [5/10], Loss: 0.4006\n",
            "Epoch [6/10], Loss: 0.3744\n",
            "Epoch [7/10], Loss: 0.1820\n",
            "Epoch [8/10], Loss: 0.2762\n",
            "Epoch [9/10], Loss: 0.2456\n",
            "Epoch [10/10], Loss: 0.1159\n",
            "Accuracy: 0.8919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID52: 29"
      ],
      "metadata": {
        "id": "x8l_UBrFUO-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 29  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GAI46sTGwJk",
        "outputId": "43e11d9e-6160-46a5-a857-296f64c4b9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5683\n",
            "Epoch [2/10], Loss: 0.6107\n",
            "Epoch [3/10], Loss: 0.4976\n",
            "Epoch [4/10], Loss: 0.3759\n",
            "Epoch [5/10], Loss: 0.2898\n",
            "Epoch [6/10], Loss: 0.6791\n",
            "Epoch [7/10], Loss: 0.4550\n",
            "Epoch [8/10], Loss: 0.2221\n",
            "Epoch [9/10], Loss: 0.1403\n",
            "Epoch [10/10], Loss: 0.2874\n",
            "Accuracy: 0.8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID53: 45"
      ],
      "metadata": {
        "id": "K8UnhnOzUPJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 45  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-ZRjnhhGwyI",
        "outputId": "f595202d-5572-4c48-c2dd-c5d59cbc2d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8273\n",
            "Epoch [2/10], Loss: 0.3736\n",
            "Epoch [3/10], Loss: 0.4439\n",
            "Epoch [4/10], Loss: 0.5267\n",
            "Epoch [5/10], Loss: 0.2413\n",
            "Epoch [6/10], Loss: 0.1165\n",
            "Epoch [7/10], Loss: 0.2268\n",
            "Epoch [8/10], Loss: 0.1592\n",
            "Epoch [9/10], Loss: 0.2348\n",
            "Epoch [10/10], Loss: 0.0930\n",
            "Accuracy: 0.9028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID54: 125922"
      ],
      "metadata": {
        "id": "FIX9XbrkUPVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 125922  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sblb5PRWGxUR",
        "outputId": "1849804c-4d58-40ad-e783-8df34b45dae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7484\n",
            "Epoch [2/10], Loss: 1.1360\n",
            "Epoch [3/10], Loss: 0.4406\n",
            "Epoch [4/10], Loss: 0.2962\n",
            "Epoch [5/10], Loss: 0.2426\n",
            "Epoch [6/10], Loss: 0.0788\n",
            "Epoch [7/10], Loss: 0.0731\n",
            "Epoch [8/10], Loss: 0.2455\n",
            "Epoch [9/10], Loss: 0.0644\n",
            "Epoch [10/10], Loss: 0.2277\n",
            "Accuracy: 0.9809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID55: 9960"
      ],
      "metadata": {
        "id": "KbGl87-KUPhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9960 # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aHQuFMQGx90",
        "outputId": "a2fe6255-e08d-43f6-a47a-be0758363b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.1461\n",
            "Epoch [2/10], Loss: 0.6053\n",
            "Epoch [3/10], Loss: 1.0406\n",
            "Epoch [4/10], Loss: 0.6747\n",
            "Epoch [5/10], Loss: 0.5201\n",
            "Epoch [6/10], Loss: 0.9662\n",
            "Epoch [7/10], Loss: 0.6516\n",
            "Epoch [8/10], Loss: 0.2981\n",
            "Epoch [9/10], Loss: 0.7435\n",
            "Epoch [10/10], Loss: 0.2616\n",
            "Accuracy: 0.8233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID56: 9964"
      ],
      "metadata": {
        "id": "XykMaPm-UPuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9964  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVRI9YnFGyi8",
        "outputId": "952f3880-f25b-428e-a2ee-0f522a2adffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.7351\n",
            "Epoch [2/10], Loss: 0.8990\n",
            "Epoch [3/10], Loss: 0.5939\n",
            "Epoch [4/10], Loss: 0.3084\n",
            "Epoch [5/10], Loss: 0.3122\n",
            "Epoch [6/10], Loss: 0.3787\n",
            "Epoch [7/10], Loss: 0.1843\n",
            "Epoch [8/10], Loss: 0.3635\n",
            "Epoch [9/10], Loss: 0.2732\n",
            "Epoch [10/10], Loss: 0.1935\n",
            "Accuracy: 0.9122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID57: 22"
      ],
      "metadata": {
        "id": "sgLsaY6mUP5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 22  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR9FmsHRGzJZ",
        "outputId": "bf8a3ced-fdc0-4991-8513-00f5ef26c7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.9153\n",
            "Epoch [2/10], Loss: 1.1205\n",
            "Epoch [3/10], Loss: 0.8081\n",
            "Epoch [4/10], Loss: 0.8976\n",
            "Epoch [5/10], Loss: 0.7231\n",
            "Epoch [6/10], Loss: 0.9096\n",
            "Epoch [7/10], Loss: 0.4405\n",
            "Epoch [8/10], Loss: 0.6210\n",
            "Epoch [9/10], Loss: 0.4733\n",
            "Epoch [10/10], Loss: 0.6931\n",
            "Accuracy: 0.8100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID58: 2079"
      ],
      "metadata": {
        "id": "iPjBiyKOUQGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 2079  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slOBNznBGz1e",
        "outputId": "5207a1aa-7364-4be2-84f9-0356e3121873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.5049\n",
            "Epoch [2/10], Loss: 1.3901\n",
            "Epoch [3/10], Loss: 1.4932\n",
            "Epoch [4/10], Loss: 1.3889\n",
            "Epoch [5/10], Loss: 1.1976\n",
            "Epoch [6/10], Loss: 0.9845\n",
            "Epoch [7/10], Loss: 1.0315\n",
            "Epoch [8/10], Loss: 0.9093\n",
            "Epoch [9/10], Loss: 1.1634\n",
            "Epoch [10/10], Loss: 1.2318\n",
            "Accuracy: 0.5743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID59: 14969"
      ],
      "metadata": {
        "id": "DCBskzEeUQTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 14969  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fmdnYEPG0Yu",
        "outputId": "7949df09-aa9e-4f70-b71a-4c46c1ddf710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.2482\n",
            "Epoch [2/10], Loss: 1.2744\n",
            "Epoch [3/10], Loss: 1.2302\n",
            "Epoch [4/10], Loss: 1.1223\n",
            "Epoch [5/10], Loss: 1.0441\n",
            "Epoch [6/10], Loss: 1.0920\n",
            "Epoch [7/10], Loss: 1.2609\n",
            "Epoch [8/10], Loss: 1.2281\n",
            "Epoch [9/10], Loss: 1.5800\n",
            "Epoch [10/10], Loss: 1.1081\n",
            "Accuracy: 0.5337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID60: 3560"
      ],
      "metadata": {
        "id": "3scdUqaAUQfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3560  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_ks55GYG07c",
        "outputId": "fb3871cf-fca3-4a23-e32c-dd778dc7db80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.7975\n",
            "Epoch [2/10], Loss: 1.7885\n",
            "Epoch [3/10], Loss: 1.7737\n",
            "Epoch [4/10], Loss: 1.7932\n",
            "Epoch [5/10], Loss: 1.7920\n",
            "Epoch [6/10], Loss: 1.7832\n",
            "Epoch [7/10], Loss: 1.7472\n",
            "Epoch [8/10], Loss: 1.7870\n",
            "Epoch [9/10], Loss: 1.7094\n",
            "Epoch [10/10], Loss: 1.7713\n",
            "Accuracy: 0.2625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID61: 14952"
      ],
      "metadata": {
        "id": "cyp2ScRKUQtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 14952  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PidRUacvG1gi",
        "outputId": "dab295b4-16cd-49fc-fb86-f174c1a7d5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.3069\n",
            "Epoch [2/10], Loss: 0.1478\n",
            "Epoch [3/10], Loss: 0.2428\n",
            "Epoch [4/10], Loss: 0.1103\n",
            "Epoch [5/10], Loss: 0.0717\n",
            "Epoch [6/10], Loss: 0.1554\n",
            "Epoch [7/10], Loss: 0.3517\n",
            "Epoch [8/10], Loss: 0.2146\n",
            "Epoch [9/10], Loss: 0.0141\n",
            "Epoch [10/10], Loss: 0.0763\n",
            "Accuracy: 0.9457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID62: 125920"
      ],
      "metadata": {
        "id": "wmm8YmtYdYqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 125920  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8WABmitG2E3",
        "outputId": "6c19093b-f962-405a-f58e-f775c6a6a7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6561\n",
            "Epoch [2/10], Loss: 0.6528\n",
            "Epoch [3/10], Loss: 0.6298\n",
            "Epoch [4/10], Loss: 0.6924\n",
            "Epoch [5/10], Loss: 0.6469\n",
            "Epoch [6/10], Loss: 0.6853\n",
            "Epoch [7/10], Loss: 0.7803\n",
            "Epoch [8/10], Loss: 0.7304\n",
            "Epoch [9/10], Loss: 0.7056\n",
            "Epoch [10/10], Loss: 0.6113\n",
            "Accuracy: 0.5800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID63: 23"
      ],
      "metadata": {
        "id": "OOeFMqFydZr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 23  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYss7LlqG2_d",
        "outputId": "d715229e-e69c-4bdf-e8a1-eaddc2503313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.9581\n",
            "Epoch [2/10], Loss: 0.9892\n",
            "Epoch [3/10], Loss: 0.9708\n",
            "Epoch [4/10], Loss: 0.9396\n",
            "Epoch [5/10], Loss: 1.0600\n",
            "Epoch [6/10], Loss: 1.0222\n",
            "Epoch [7/10], Loss: 0.8828\n",
            "Epoch [8/10], Loss: 1.0116\n",
            "Epoch [9/10], Loss: 0.8553\n",
            "Epoch [10/10], Loss: 0.8614\n",
            "Accuracy: 0.5661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID64: 3904"
      ],
      "metadata": {
        "id": "j0ZiCc7_dZ5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3904  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMK945GWG3hN",
        "outputId": "b8101859-268f-42a1-a493-30b6b5bf05fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2033\n",
            "Epoch [2/10], Loss: 0.2305\n",
            "Epoch [3/10], Loss: 0.1396\n",
            "Epoch [4/10], Loss: 0.4330\n",
            "Epoch [5/10], Loss: 0.5676\n",
            "Epoch [6/10], Loss: 0.1745\n",
            "Epoch [7/10], Loss: 0.2576\n",
            "Epoch [8/10], Loss: 0.3292\n",
            "Epoch [9/10], Loss: 0.9026\n",
            "Epoch [10/10], Loss: 0.1090\n",
            "Accuracy: 0.8112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID65: 3022"
      ],
      "metadata": {
        "id": "JgmWq_NbdaFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3022  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYLMB8ebG4Dj",
        "outputId": "d7256e93-6840-42fc-9b93-93353cb2d530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.3624\n",
            "Epoch [2/10], Loss: 2.3273\n",
            "Epoch [3/10], Loss: 2.0606\n",
            "Epoch [4/10], Loss: 1.8122\n",
            "Epoch [5/10], Loss: 1.6415\n",
            "Epoch [6/10], Loss: 1.5427\n",
            "Epoch [7/10], Loss: 1.5094\n",
            "Epoch [8/10], Loss: 1.1993\n",
            "Epoch [9/10], Loss: 1.2095\n",
            "Epoch [10/10], Loss: 1.0983\n",
            "Accuracy: 0.6263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID66: 9985"
      ],
      "metadata": {
        "id": "k1saJ1SSdaTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9985  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL5D5yNTG4k8",
        "outputId": "6b53163c-e0e3-4ce6-b76d-9e3a00ced88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.3718\n",
            "Epoch [2/10], Loss: 1.3923\n",
            "Epoch [3/10], Loss: 1.4622\n",
            "Epoch [4/10], Loss: 1.2558\n",
            "Epoch [5/10], Loss: 1.3364\n",
            "Epoch [6/10], Loss: 1.1151\n",
            "Epoch [7/10], Loss: 1.4405\n",
            "Epoch [8/10], Loss: 1.4199\n",
            "Epoch [9/10], Loss: 1.1781\n",
            "Epoch [10/10], Loss: 1.5860\n",
            "Accuracy: 0.4943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID67: 9910"
      ],
      "metadata": {
        "id": "NmZiZ5TQdagj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9910  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80yYihXiG5Qe",
        "outputId": "64716f96-98c0-45c5-b70d-823c1fe3db9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4531\n",
            "Epoch [2/10], Loss: 0.3834\n",
            "Epoch [3/10], Loss: 0.5013\n",
            "Epoch [4/10], Loss: 0.3747\n",
            "Epoch [5/10], Loss: 0.5048\n",
            "Epoch [6/10], Loss: 0.4651\n",
            "Epoch [7/10], Loss: 0.6111\n",
            "Epoch [8/10], Loss: 0.3295\n",
            "Epoch [9/10], Loss: 0.2774\n",
            "Epoch [10/10], Loss: 0.2270\n",
            "Accuracy: 0.7843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID68: 14970"
      ],
      "metadata": {
        "id": "hbFnAU79das-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 14970  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKeMP42OG6Nn",
        "outputId": "592d58b8-fa68-4efb-faed-dc37f73a22e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.1258\n",
            "Epoch [2/10], Loss: 0.0953\n",
            "Epoch [3/10], Loss: 0.1113\n",
            "Epoch [4/10], Loss: 0.0469\n",
            "Epoch [5/10], Loss: 0.0619\n",
            "Epoch [6/10], Loss: 0.0536\n",
            "Epoch [7/10], Loss: 0.0102\n",
            "Epoch [8/10], Loss: 0.0102\n",
            "Epoch [9/10], Loss: 0.0825\n",
            "Epoch [10/10], Loss: 0.2505\n",
            "Accuracy: 0.9699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID69: 3021"
      ],
      "metadata": {
        "id": "HXGqTwEwda5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3021  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IFS9-iVG6yG",
        "outputId": "526e57ee-bdfb-42ed-a69d-f82042ddede2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: nan\n",
            "Epoch [2/10], Loss: nan\n",
            "Epoch [3/10], Loss: nan\n",
            "Epoch [4/10], Loss: nan\n",
            "Epoch [5/10], Loss: nan\n",
            "Epoch [6/10], Loss: nan\n",
            "Epoch [7/10], Loss: nan\n",
            "Epoch [8/10], Loss: nan\n",
            "Epoch [9/10], Loss: nan\n",
            "Epoch [10/10], Loss: nan\n",
            "Accuracy: 0.9497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID70: 3481"
      ],
      "metadata": {
        "id": "_SGwxPNTdbG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 3481  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ3GQM-8G7UW",
        "outputId": "b7bc8805-7537-4381-db6e-209e9bd7ea9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6701\n",
            "Epoch [2/10], Loss: 0.5188\n",
            "Epoch [3/10], Loss: 0.4814\n",
            "Epoch [4/10], Loss: 0.3009\n",
            "Epoch [5/10], Loss: 0.4821\n",
            "Epoch [6/10], Loss: 0.1372\n",
            "Epoch [7/10], Loss: 0.1265\n",
            "Epoch [8/10], Loss: 0.1033\n",
            "Epoch [9/10], Loss: 0.1955\n",
            "Epoch [10/10], Loss: 0.4077\n",
            "Accuracy: 0.9519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID71: 3573"
      ],
      "metadata": {
        "id": "pRv7Cn0GdbT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 9946  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "id": "hLJq01izG8BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID72: 146824"
      ],
      "metadata": {
        "id": "yyid9hePdbi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146824  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qn3SoLvG8kt",
        "outputId": "759ddc48-eab3-453b-d2f8-e5d53b1aeb41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.0078\n",
            "Epoch [2/10], Loss: 0.2178\n",
            "Epoch [3/10], Loss: 0.2980\n",
            "Epoch [4/10], Loss: 0.1871\n",
            "Epoch [5/10], Loss: 0.1209\n",
            "Epoch [6/10], Loss: 0.2171\n",
            "Epoch [7/10], Loss: 0.1167\n",
            "Epoch [8/10], Loss: 0.1056\n",
            "Epoch [9/10], Loss: 0.0560\n",
            "Epoch [10/10], Loss: 0.1168\n",
            "Accuracy: 0.9625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID73: 146820"
      ],
      "metadata": {
        "id": "ZErycBTkjcTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146820  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaHt0xXlG9Ur",
        "outputId": "2e4369e0-fb0d-41ec-fb35-9ab517b1a4ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.1358\n",
            "Epoch [2/10], Loss: 0.1010\n",
            "Epoch [3/10], Loss: 0.0912\n",
            "Epoch [4/10], Loss: 0.3462\n",
            "Epoch [5/10], Loss: 0.1265\n",
            "Epoch [6/10], Loss: 0.3241\n",
            "Epoch [7/10], Loss: 0.0289\n",
            "Epoch [8/10], Loss: 0.0818\n",
            "Epoch [9/10], Loss: 0.0911\n",
            "Epoch [10/10], Loss: 0.0320\n",
            "Accuracy: 0.9783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID74: 146822"
      ],
      "metadata": {
        "id": "ApnHqxGOjclf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146822  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5CF3BiWG92o",
        "outputId": "166deb4c-9af3-4ab0-bc16-1100eab97d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.3144\n",
            "Epoch [2/10], Loss: 0.6705\n",
            "Epoch [3/10], Loss: 0.4327\n",
            "Epoch [4/10], Loss: 0.6459\n",
            "Epoch [5/10], Loss: 0.4002\n",
            "Epoch [6/10], Loss: 0.4064\n",
            "Epoch [7/10], Loss: 0.5871\n",
            "Epoch [8/10], Loss: 0.5033\n",
            "Epoch [9/10], Loss: 0.2537\n",
            "Epoch [10/10], Loss: 0.4168\n",
            "Accuracy: 0.8636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID75: 146195"
      ],
      "metadata": {
        "id": "Ybce50ysjc0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146195  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JeV60LfG-X4",
        "outputId": "837072b1-c6a8-4fa5-942b-2f89500cb5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7639\n",
            "Epoch [2/10], Loss: 0.7727\n",
            "Epoch [3/10], Loss: 0.8116\n",
            "Epoch [4/10], Loss: 1.0752\n",
            "Epoch [5/10], Loss: 0.9051\n",
            "Epoch [6/10], Loss: 0.5998\n",
            "Epoch [7/10], Loss: 0.7801\n",
            "Epoch [8/10], Loss: 0.7414\n",
            "Epoch [9/10], Loss: 0.8102\n",
            "Epoch [10/10], Loss: 0.8910\n",
            "Accuracy: 0.7438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID76: 146800"
      ],
      "metadata": {
        "id": "hS7jGUhzjdCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146800  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DbGjO9_G-58",
        "outputId": "9827eb9d-3757-4446-8aec-825a26ae4a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.8622\n",
            "Epoch [2/10], Loss: 1.4900\n",
            "Epoch [3/10], Loss: 1.1354\n",
            "Epoch [4/10], Loss: 0.9604\n",
            "Epoch [5/10], Loss: 0.6071\n",
            "Epoch [6/10], Loss: 0.6917\n",
            "Epoch [7/10], Loss: 0.4655\n",
            "Epoch [8/10], Loss: 0.5691\n",
            "Epoch [9/10], Loss: 0.3564\n",
            "Epoch [10/10], Loss: 0.3355\n",
            "Accuracy: 0.9537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID77: 146817"
      ],
      "metadata": {
        "id": "Cp2KgzM5jdPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146817  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE6RjJ76G_aj",
        "outputId": "94528aea-70b5-48a2-c38b-024f3ecbd618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.4363\n",
            "Epoch [2/10], Loss: 1.5182\n",
            "Epoch [3/10], Loss: 0.9396\n",
            "Epoch [4/10], Loss: 0.9890\n",
            "Epoch [5/10], Loss: 1.1000\n",
            "Epoch [6/10], Loss: 0.7605\n",
            "Epoch [7/10], Loss: 0.4802\n",
            "Epoch [8/10], Loss: 0.8595\n",
            "Epoch [9/10], Loss: 1.2034\n",
            "Epoch [10/10], Loss: 0.4989\n",
            "Accuracy: 0.7224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID78: 146819"
      ],
      "metadata": {
        "id": "yXXQpbjwjdb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146819  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM8wd_uKG_9I",
        "outputId": "eb03b08d-f729-4d79-d80a-4eaafa05370f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5807\n",
            "Epoch [2/10], Loss: 0.1377\n",
            "Epoch [3/10], Loss: 0.5074\n",
            "Epoch [4/10], Loss: 0.2223\n",
            "Epoch [5/10], Loss: 0.0579\n",
            "Epoch [6/10], Loss: 0.0759\n",
            "Epoch [7/10], Loss: 0.1981\n",
            "Epoch [8/10], Loss: 0.0467\n",
            "Epoch [9/10], Loss: 0.1606\n",
            "Epoch [10/10], Loss: 0.0927\n",
            "Accuracy: 0.9074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID79: 146821"
      ],
      "metadata": {
        "id": "FQWP6NUVjdoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 146821  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng12D2pJHAaU",
        "outputId": "9f141212-d6f9-4c6a-d119-def3e96d2454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.9359\n",
            "Epoch [2/10], Loss: 0.5941\n",
            "Epoch [3/10], Loss: 0.6852\n",
            "Epoch [4/10], Loss: 0.3264\n",
            "Epoch [5/10], Loss: 0.1279\n",
            "Epoch [6/10], Loss: 0.3459\n",
            "Epoch [7/10], Loss: 0.5113\n",
            "Epoch [8/10], Loss: 0.6479\n",
            "Epoch [9/10], Loss: 0.0682\n",
            "Epoch [10/10], Loss: 0.4343\n",
            "Accuracy: 0.8931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID80: 14954"
      ],
      "metadata": {
        "id": "R1dUVRBFjd0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 14954  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWZQIM4mHBBt",
        "outputId": "4f192a14-7baa-40d7-f5d0-4a8bd26387b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6958\n",
            "Epoch [2/10], Loss: 0.6255\n",
            "Epoch [3/10], Loss: 0.6655\n",
            "Epoch [4/10], Loss: 0.5182\n",
            "Epoch [5/10], Loss: 0.4262\n",
            "Epoch [6/10], Loss: 0.4989\n",
            "Epoch [7/10], Loss: 0.5278\n",
            "Epoch [8/10], Loss: 0.5725\n",
            "Epoch [9/10], Loss: 0.3996\n",
            "Epoch [10/10], Loss: 0.5399\n",
            "Accuracy: 0.7315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID81: 167141"
      ],
      "metadata": {
        "id": "hZqVKYjojeA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 167141  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nyCWQB4HBfN",
        "outputId": "78c8ce74-157c-4c93-96cb-f8c8a25fdb52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.3436\n",
            "Epoch [2/10], Loss: 0.3594\n",
            "Epoch [3/10], Loss: 0.1749\n",
            "Epoch [4/10], Loss: 0.4268\n",
            "Epoch [5/10], Loss: 0.5808\n",
            "Epoch [6/10], Loss: 0.3436\n",
            "Epoch [7/10], Loss: 0.3714\n",
            "Epoch [8/10], Loss: 0.1146\n",
            "Epoch [9/10], Loss: 0.2928\n",
            "Epoch [10/10], Loss: 0.2401\n",
            "Accuracy: 0.9260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID82: 167140"
      ],
      "metadata": {
        "id": "S19sCYYBjeNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 167140  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDWrpR-jHB60",
        "outputId": "33353124-4371-4580-8d03-8d69c3729470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5412\n",
            "Epoch [2/10], Loss: 0.1624\n",
            "Epoch [3/10], Loss: 0.1953\n",
            "Epoch [4/10], Loss: 0.1324\n",
            "Epoch [5/10], Loss: 0.0358\n",
            "Epoch [6/10], Loss: 0.2913\n",
            "Epoch [7/10], Loss: 0.2629\n",
            "Epoch [8/10], Loss: 0.0061\n",
            "Epoch [9/10], Loss: 0.0200\n",
            "Epoch [10/10], Loss: 0.0457\n",
            "Accuracy: 0.9498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID83: 167125"
      ],
      "metadata": {
        "id": "LDgS_tZ8jeZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "task_id = 167125  # Example task ID from OpenML\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load data\n",
        "X, y = load_openml_data(task_id)\n",
        "\n",
        "# Initialize data loaders\n",
        "train_loader, val_loader = get_data_loaders(X, y, batch_size=batch_size)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "num_classes = len(np.unique(y))\n",
        "input_size = X.shape[1]  # Number of features\n",
        "model = ResNetTabular(input_size=input_size, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for features, labels in val_loader:\n",
        "        outputs = model(features)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Klv-0LYHCeN",
        "outputId": "604be379-0ae1-4723-cda7-76e4a12ab9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2874\n",
            "Epoch [2/10], Loss: 0.0253\n",
            "Epoch [3/10], Loss: 0.0332\n",
            "Epoch [4/10], Loss: 0.0362\n",
            "Epoch [5/10], Loss: 0.0667\n",
            "Epoch [6/10], Loss: 0.0069\n",
            "Epoch [7/10], Loss: 0.0061\n",
            "Epoch [8/10], Loss: 0.0323\n",
            "Epoch [9/10], Loss: 0.0654\n",
            "Epoch [10/10], Loss: 0.0032\n",
            "Accuracy: 0.9680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID84: 167124"
      ],
      "metadata": {
        "id": "y5x3ad8gjenJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task ID85: 167121"
      ],
      "metadata": {
        "id": "Q82DhhLtjezZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "An2d6-8E4hx5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}